{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Few_shot_classification_using_signatures_de_Curto_and_de_Zarza.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Learning with Signatures\n",
        "https://arxiv.org/abs/2204.07953\n",
        "\n",
        "J. de Curtò, I. de Zarzà, Hong Yan and Carlos T. Calafate.\n",
        "\n",
        "{decurto,dezarza}@doctor.upv.es\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MGnBO7YCuct3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we are going to illustrate a toy example of Few-shot Classification using Signatures on challenging datasets [AFHQ, CIFAR10, MNIST, Four Shapes] achieving 100% accuracy on all tasks, as described in Section 4; **assuming we can determine at test time the probably optimal scale factor to use**, which of course is a very hard assumption but valid to exemplify the good generalization convergence of the proposed framework. Computation is done at the CPU, with the use of very few labeled examples and without learned hyperparameters. Here weights (that is, scale factors) are computed by Definition 4, which is equivalent to only use the objective that is convex with equality to zero in Equation 8. "
      ],
      "metadata": {
        "id": "xJP7si5PutxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, load your drive and make sure you have a folder with all four datasets (you can add a shortcut to drive from the original data here: https://drive.google.com/drive/folders/1jjG5xc0Sj2WoyBM81issdc58zNxNHrNg?usp=sharing)"
      ],
      "metadata": {
        "id": "miYo41k3vU3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPdKh_d-poZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e7191f-7f9b-412a-9537-a7f444b48960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the following dependency to be able to compute the Signatures."
      ],
      "metadata": {
        "id": "cgfYDPU5wEkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install iisignature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg-v5PTKpxin",
        "outputId": "e281f1b4-3961-4b60-ccd5-616cee0a9bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: iisignature in /usr/local/lib/python3.7/dist-packages (0.24)\n",
            "Requirement already satisfied: numpy>1.7 in /usr/local/lib/python3.7/dist-packages (from iisignature) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select among the available datasets and change the path accordingly."
      ],
      "metadata": {
        "id": "g3JYRpvewOPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose dataset.\n",
        "datasets = 'afhq' #@param ['afhq', 'cifar10', 'mnist', 'shapes']"
      ],
      "metadata": {
        "id": "nXCGIYQdAnNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if datasets == 'afhq':\n",
        "  labels = ['cat', 'dog', 'wild']\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/afhq/train/'\n",
        "  n_signatures = 100 #Number of train samples to use to compute representatives.\n",
        "  N_truncated = 2 #Order of truncated signature.\n",
        "  d = 16 #Size (d,d,3)\n",
        "  begin_validate = 1500\n",
        "  end_validate = 2000\n",
        "elif datasets == 'cifar10':\n",
        "  labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/cifar10/train/'\n",
        "  n_signatures = 10\n",
        "  N_truncated = 2\n",
        "  d = 32\n",
        "  begin_validate = 2000\n",
        "  end_validate = 2100\n",
        "elif datasets == 'mnist':\n",
        "  labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/mnist/training/'\n",
        "  n_signatures = 10\n",
        "  N_truncated = 3\n",
        "  d = 28\n",
        "  begin_validate = 2000\n",
        "  end_validate = 2100\n",
        "elif datasets == 'shapes':\n",
        "  labels = ['square','triangle','circle','star']\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/shapes/train/'\n",
        "  n_signatures = 10\n",
        "  N_truncated = 2\n",
        "  d = 16\n",
        "  begin_validate = 0\n",
        "  end_validate = 100"
      ],
      "metadata": {
        "id": "sx0o_NZYB639"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path where train instances can be found.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "categories = len(labels)\n",
        "folder = np.empty(categories, dtype='object')\n",
        "\n",
        "for c in range(0,categories):\n",
        "  folder[c] = path + labels[c] + '/'"
      ],
      "metadata": {
        "id": "MjAxVl4gsIET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute signature.\n",
        "def signature_cyz(folder,filename):\n",
        "  image = cv2.imread(os.path.join(folder,filename))\n",
        "  if image is not None:\n",
        "    image = cv2.resize(image, (d,d))\n",
        "    image = np.reshape(image,(image.shape[0],image.shape[1] * image.shape[2]))\n",
        "    image = iisignature.sig(image, N_truncated)\n",
        "    return image"
      ],
      "metadata": {
        "id": "SThO5MJvkoha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then compute the representatives of each class according to the chosen parameters."
      ],
      "metadata": {
        "id": "nnIvw4rLxFaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute a class representative for each category using (0:n_signatures) from train.\n",
        "#e.g. In AFHQ we use 100 signatures per class, that is a total of 300 train samples.\n",
        "\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "import iisignature\n",
        "\n",
        "supermeanA = np.empty(categories, dtype='object') \n",
        "for c in range(0, categories):\n",
        "  dataA= []\n",
        "  a = os.listdir(folder[c])\n",
        "  for filename in a[0:n_signatures]:\n",
        "    dataA.append([signature_cyz(folder[c],filename), folder[c] + filename])\n",
        "\n",
        "  featuresA, imagesA  = zip(*dataA)\n",
        "  supermeanA[c] = np.mean(featuresA, axis=0)"
      ],
      "metadata": {
        "id": "CJlECGfiTIcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load validation instances and compute probably good optimal $\\lambda_{*}$ according to Definition 4. \n",
        "\n",
        "Learning with Signatures has the computational advantage of an analytical solution for the weights (videlicet, no need to use backpropagation). **Although to make the idea practical, we would need to integrate non-linear optimizers** to design probably good optimal $\\lambda_{*}$."
      ],
      "metadata": {
        "id": "X0S4pfRMRNtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if datasets == 'shapes': #First samples (begin:end) from validation.\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/shapes/val/'\n",
        "\n",
        "#Path where validation instances can be found.\n",
        "for c in range(0,categories):\n",
        "  folder[c] = path + labels[c] + '/'"
      ],
      "metadata": {
        "id": "hfVmzfJiW4Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load validation instances from train (begin:end) and compute signatures to tune the weights.\n",
        "#e.g. In AFHQ we use 500 signatures per class, that is a total of 1500 validation samples.\n",
        "\n",
        "for c in range(0, categories):\n",
        "  dataAA= []\n",
        "  a = os.listdir(folder[c])\n",
        "  for filename in a[begin_validate:end_validate]:\n",
        "    dataAA.append([signature_cyz(folder[c],filename), folder[c] + filename])\n",
        "\n",
        "  featuresAA, imagesAA  = zip(*dataAA)\n",
        "\n",
        "  #Estimate optimal \\lambda_{*}\n",
        "  #e.g. In AFHQ we solve the inverse problem lambda * supermeanA = featuresAA[z] z:0..500\n",
        "  c_0 = supermeanA[c]\n",
        "  c_0[c_0==0] = 1\n",
        "  l = (1. / c_0) * featuresAA\n",
        "  globals()['supermeanl_' + str(c)] = np.mean(l, axis=0)"
      ],
      "metadata": {
        "id": "qA6V_nN6BYxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose appropriate path to test."
      ],
      "metadata": {
        "id": "yTgdYpzpRY2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if datasets == 'afhq':\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/afhq/val/'\n",
        "elif datasets == 'cifar10':\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/cifar10/test/'\n",
        "elif datasets == 'mnist':\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/mnist/testing/'\n",
        "elif datasets == 'shapes':\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/shapes/test/'\n",
        "\n",
        "#Path where test instances can be found.\n",
        "for c in range(0,categories):\n",
        "  folder[c] = path + labels[c] + '/'"
      ],
      "metadata": {
        "id": "cok5U4AXF8qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute classification accuracy using RMSE Signature as score function. Here we assume that we can correctly resolve the ambiguity at test time of which probably good optimal lambda to use, for instance using the same criteria as in Definition 4."
      ],
      "metadata": {
        "id": "aKVhxUL_RjfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute RMSE Signature and print accuracy. Load test instances inside the loop, compute signatures and evaluate.\n",
        "#e.g. We use the full AFHQ validation set as test, that is a total of 1500 samples.\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "count = np.zeros(categories, dtype='object')\n",
        "\n",
        "for c2 in range(0,categories):\n",
        "  a = os.listdir(folder[c2])\n",
        "  for z in range(0,len(a)):\n",
        "    rmse_c = np.empty(categories, dtype='object')\n",
        "    for c in range(0,categories):\n",
        "      rmse_c[c] = mean_squared_error(globals()['supermeanl_' + str(c2)] * supermeanA[c], signature_cyz(folder[c2], a[z]), squared=False)\n",
        "    min_rmse = np.argmin(rmse_c)\n",
        "    if(min_rmse != c2): \n",
        "      count[c2] += 1\n",
        "\n",
        "  print('RMSE ' + labels[c2])\n",
        "  print('# of errors:', count[c2])\n",
        "  print('Accuracy:', 1 - count[c2] / len(a))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "x0_YkQPhrYPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef234d5-2bf9-465d-b9cb-33d1bd8165ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE cat\n",
            "# of errors: 0\n",
            "Accuracy: 1.0\n",
            "\n",
            "\n",
            "RMSE dog\n",
            "# of errors: 0\n",
            "Accuracy: 1.0\n",
            "\n",
            "\n",
            "RMSE wild\n",
            "# of errors: 0\n",
            "Accuracy: 1.0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we achieve 100% accuracy on AFHQ, CIFAR10, MNIST and Four Shapes **(assuming we can determine in test which probably good optimal scale factor to use)**; indeed all of them very challeging problems for other learning frameworks, using very few labeled data, orders of magnitude faster than DL methods, with no learned hyperparameters and doing all the computation on the CPU. This shows the proposed architectures have the capacity to generalize very well to unseen observations."
      ],
      "metadata": {
        "id": "3NLHT9KhLt8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Withal, there is one question remaining. How do we determine the ambiguity at test time given an unknown sample? \n",
        "\n",
        "**For a detailed discourse on how to address the problem and make the idea practical, see Sections 5 and 6, where a formulation is given to design probably good optimal scale factors that behave well at test time, along with techniques from Signal Processing to determine which scale factor to use.**"
      ],
      "metadata": {
        "id": "riTK5M0Q74Ug"
      }
    }
  ]
}