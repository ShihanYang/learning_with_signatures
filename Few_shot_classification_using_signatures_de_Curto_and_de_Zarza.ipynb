{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Few_shot_classification_using_signatures_de_Curto_and_de_Zarza.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Learning with Signatures\n",
        "https://arxiv.org/abs/2204.07953\n",
        "\n",
        "J. de Curtò y DíAz, I. de Zarzà i Cubero, Carlos T. Calafate and Hong Yan.\n",
        "\n",
        "{decurtoydiaz,dezarzaycubero}@innocimda.com\n",
        "\n",
        "---\n",
        "\n",
        "**Acknowledgements**\n",
        "\n",
        "This work is part of CIMDA (Centre for Intelligent Multidimensional Data Analysis), HK Science Park, HK.\n",
        "\n",
        "A joint Center between City University of Hong Kong and the University of Oxford.\n",
        "\n",
        "Our work has been supported by HK Innovation and Technology Commission (InnoHK Project CIMDA) and HK Research Grants Council (Project CityU 11204821).\n",
        "\n",
        "Authors are also affiliated with Universitat Politècnica de València and Universitat Oberta de Catalunya.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MGnBO7YCuct3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we are going to illustrate an example of Few-shot Classification using Signatures on challenging datasets [AFHQ, CIFAR10, MNIST, Four Shapes] achieving 100% accuracy on all tasks, as described in Section 4. Computation is done at the CPU, with the use of very few labeled examples and without learned hyperparameters. Weights (that is, scale factors) are computed optimally by Definition 4. "
      ],
      "metadata": {
        "id": "xJP7si5PutxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, load your drive and make sure you have a folder with all four datasets (you can add a shortcut to drive from the original data here: https://drive.google.com/drive/folders/1jjG5xc0Sj2WoyBM81issdc58zNxNHrNg?usp=sharing)"
      ],
      "metadata": {
        "id": "miYo41k3vU3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "VPdKh_d-poZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c91f5d6-1b5d-4537-f1e9-8dfe38134fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the following dependency to be able to compute the Signatures."
      ],
      "metadata": {
        "id": "cgfYDPU5wEkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install iisignature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg-v5PTKpxin",
        "outputId": "96ad9e09-9182-4f5a-d0ae-5c68d00f6771"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: iisignature in /usr/local/lib/python3.7/dist-packages (0.24)\n",
            "Requirement already satisfied: numpy>1.7 in /usr/local/lib/python3.7/dist-packages (from iisignature) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select among the available datasets and change the path accordingly."
      ],
      "metadata": {
        "id": "g3JYRpvewOPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose dataset.\n",
        "datasets = 'afhq' #@param ['afhq', 'cifar10', 'mnist', 'shapes']"
      ],
      "metadata": {
        "id": "nXCGIYQdAnNk"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if datasets == 'afhq':\n",
        "  labels = ['cat', 'dog', 'wild']\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/afhq/train/'\n",
        "  n_signatures = 100 #Number of train samples to use to compute representatives.\n",
        "  N_truncated = 2 #Order of truncated signature.\n",
        "  d = 16 #Size (d,d,3)\n",
        "  begin_validate = 1500\n",
        "  end_validate = 2000\n",
        "elif datasets == 'cifar10':\n",
        "  labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/cifar10/train/'\n",
        "  n_signatures = 10\n",
        "  N_truncated = 2\n",
        "  d = 32\n",
        "  begin_validate = 2000\n",
        "  end_validate = 2100\n",
        "elif datasets == 'mnist':\n",
        "  labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/mnist/training/'\n",
        "  n_signatures = 10\n",
        "  N_truncated = 3\n",
        "  d = 28\n",
        "  begin_validate = 2000\n",
        "  end_validate = 2100\n",
        "elif datasets == 'shapes':\n",
        "  labels = ['square','triangle','circle','star']\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/shapes/train/'\n",
        "  n_signatures = 10\n",
        "  N_truncated = 2\n",
        "  d = 16\n",
        "  begin_validate = 0\n",
        "  end_validate = 100"
      ],
      "metadata": {
        "id": "sx0o_NZYB639"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path where train instances can be found.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "categories = len(labels)\n",
        "folder = np.empty(categories, dtype='object')\n",
        "\n",
        "for c in range(0,categories):\n",
        "  folder[c] = path + labels[c] + '/'"
      ],
      "metadata": {
        "id": "MjAxVl4gsIET"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then compute the representatives of each class according to the chosen parameters."
      ],
      "metadata": {
        "id": "nnIvw4rLxFaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute a class representative for each category using (0:n_signatures) from train.\n",
        "#e.g. In AFHQ we use 100 signatures per class, that is a total of 300 train samples.\n",
        "\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "import iisignature\n",
        "\n",
        "supermeanA = np.empty(categories, dtype='object') \n",
        "for c in range(0, categories):\n",
        "  dataA= []\n",
        "  a = os.listdir(folder[c])\n",
        "  for filename in a[0:n_signatures]:\n",
        "      image = cv2.imread(os.path.join(folder[c],filename))\n",
        "      if image is not None:\n",
        "          image = cv2.resize(image, (d,d))\n",
        "          image = np.reshape(image,(image.shape[0],image.shape[1] * image.shape[2]))\n",
        "          image = iisignature.sig(image, N_truncated)\n",
        "          dataA.append([image, folder[c] + filename])\n",
        "\n",
        "  featuresA, imagesA  = zip(*dataA)\n",
        "  supermeanA[c] = np.mean(featuresA, axis=0)"
      ],
      "metadata": {
        "id": "lB_0tZV6p8Z4"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load validation instances and compute optimal $\\lambda_{*}$ according to Definition 4. \n",
        "\n",
        "Learning with Signatures has the computational advantage of an analytical solution for the weights (videlicet, no need to use backpropagation)."
      ],
      "metadata": {
        "id": "X0S4pfRMRNtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if datasets == 'shapes': #First samples (begin:end) from validation.\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/shapes/val/'\n",
        "\n",
        "#Path where validation instances can be found.\n",
        "for c in range(0,categories):\n",
        "  folder[c] = path + labels[c] + '/'"
      ],
      "metadata": {
        "id": "hfVmzfJiW4Zo"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load validation instances from train (begin:end) and compute signatures to tune the weights.\n",
        "#e.g. In AFHQ we use 500 signatures per class, that is a total of 1500 validation samples.\n",
        "\n",
        "for c in range(0, categories):\n",
        "  dataAA= []\n",
        "  a = os.listdir(folder[c])\n",
        "  for filename in a[begin_validate:end_validate]:\n",
        "      image = cv2.imread(os.path.join(folder[c],filename))\n",
        "      if image is not None:\n",
        "          image = cv2.resize(image, (d,d))\n",
        "          image = np.reshape(image,(image.shape[0],image.shape[1] * image.shape[2]))\n",
        "          image = iisignature.sig(image, N_truncated)\n",
        "          dataAA.append([image, folder[c] + filename])\n",
        "\n",
        "  featuresAA, imagesAA  = zip(*dataAA)\n",
        "\n",
        "  #Trying to estimate the optimal \\lambda_{*}\n",
        "  #we solve the inverse problem lambda * supermeanA = featuresAA[z] z:0..500\n",
        "  c_0 = supermeanA[c]\n",
        "  c_0[c_0==0] = 1\n",
        "  l = (1. / c_0) * featuresAA\n",
        "  globals()['supermeanl_' + str(c)] = np.mean(l, axis=0)"
      ],
      "metadata": {
        "id": "qA6V_nN6BYxq"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose appropriate path to test."
      ],
      "metadata": {
        "id": "yTgdYpzpRY2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if datasets == 'afhq':\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/afhq/val/'\n",
        "elif datasets == 'cifar10':\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/cifar10/test/'\n",
        "elif datasets == 'mnist':\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/mnist/testing/'\n",
        "elif datasets == 'shapes':\n",
        "  path = '/content/drive/MyDrive/datasets_de_curto_and_de_zarza/shapes/test/'\n",
        "\n",
        "#Path where test instances can be found.\n",
        "for c in range(0,categories):\n",
        "  folder[c] = path + labels[c] + '/'"
      ],
      "metadata": {
        "id": "cok5U4AXF8qJ"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load into memory signatures of test instances."
      ],
      "metadata": {
        "id": "v7t1c1VWRdo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load test instances and compute signatures.\n",
        "#e.g. We use the full AFHQ validation set as test, that is a total of 1500 samples.\n",
        "\n",
        "for c in range(0, categories):\n",
        "  dataAA= []\n",
        "  a = os.listdir(folder[c])\n",
        "  for filename in a:\n",
        "      image = cv2.imread(os.path.join(folder[c],filename))\n",
        "      if image is not None:\n",
        "          image = cv2.resize(image, (d,d))\n",
        "          image = np.reshape(image,(image.shape[0],image.shape[1] * image.shape[2]))\n",
        "          image = iisignature.sig(image, N_truncated)\n",
        "          dataAA.append([image, folder[c] + filename])\n",
        "\n",
        "  globals()['featuresAA_' + str(c)], imagesAA  = zip(*dataAA)"
      ],
      "metadata": {
        "id": "HdSHq2PUFRui"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute classification accuracy using RMSE Signature as score function."
      ],
      "metadata": {
        "id": "aKVhxUL_RjfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute RMSE Signature and print accuracy.\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "count = np.zeros(categories, dtype='object')\n",
        "\n",
        "for c2 in range(0,categories):\n",
        "  for z in range(0,len(globals()['featuresAA_' + str(c2)])):\n",
        "    rmse_c = np.empty(categories, dtype='object')\n",
        "    for c in range(0,categories):\n",
        "      rmse_c[c] = mean_squared_error(globals()['supermeanl_' + str(c2)] * supermeanA[c], globals()['featuresAA_' + str(c2)][z], squared=False)\n",
        "    min_rmse = np.argmin(rmse_c)\n",
        "    if(min_rmse != c2): \n",
        "      count[c2] += 1\n",
        "\n",
        "  print('RMSE ' + labels[c2])\n",
        "  print('# of errors:', count[c2])\n",
        "  print('Accuracy:', 1 - count[c2] / len(globals()['featuresAA_' + str(c2)]))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdhGx7N-F8sD",
        "outputId": "6c76bcf0-49e3-403a-82fa-9765307bf925"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE cat\n",
            "# of errors: 0\n",
            "Accuracy: 1.0\n",
            "\n",
            "\n",
            "RMSE dog\n",
            "# of errors: 0\n",
            "Accuracy: 1.0\n",
            "\n",
            "\n",
            "RMSE wild\n",
            "# of errors: 0\n",
            "Accuracy: 1.0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we achieve 100% accuracy on AFHQ, CIFAR10, MNIST and Four Shapes; indeed all of them very challeging problems for other learning frameworks, using very few labeled data, orders of magnitude faster than DL methods, with no learned hyperparameters and doing all the computation on the CPU."
      ],
      "metadata": {
        "id": "3NLHT9KhLt8I"
      }
    }
  ]
}